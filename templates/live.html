<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Live Object Detection | VisionAID</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@600&display=swap" rel="stylesheet" />
  <style>
    :root {
      --bg: #0a0f1a;
      --card: rgba(255, 255, 255, 0.05);
      --border: rgba(255, 255, 255, 0.1);
      --accent: #00fff7;
      --primary: #007bff;
      --text: #e0e0e0;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      background-color: var(--bg);
      color: var(--text);
      font-family: 'Orbitron', sans-serif;
      text-align: center;
      padding: 40px 20px;
      overflow-x: hidden;
    }

    h2 {
      font-size: 2rem;
      color: var(--accent);
      margin-bottom: 20px;
      text-shadow: 0 0 8px var(--accent);
      animation: pulseGlow 2s infinite alternate;
    }

    @keyframes pulseGlow {
      from {
        text-shadow: 0 0 5px var(--accent);
      }
      to {
        text-shadow: 0 0 15px var(--accent), 0 0 30px var(--primary);
      }
    }

    .video-card {
      display: inline-block;
      background: var(--card);
      backdrop-filter: blur(12px);
      border: 1px solid var(--border);
      border-radius: 16px;
      padding: 25px;
      box-shadow: 0 0 30px rgba(0, 255, 247, 0.1);
      transition: transform 0.3s ease;
      max-width: 800px;
      width: 100%;
    }

    .video-card:hover {
      transform: scale(1.02);
    }

    img {
      border-radius: 12px;
      border: 2px solid var(--accent);
      max-width: 100%;
      height: auto;
    }

    p {
      font-size: 1rem;
      color: #ccc;
      margin-top: 20px;
    }

    .button-group {
      display: flex;
      justify-content: center;
      gap: 15px;
      margin-top: 30px;
      flex-wrap: wrap;
    }

    button {
      padding: 12px 24px;
      font-size: 1rem;
      background: linear-gradient(90deg, var(--primary), var(--accent));
      color: black;
      font-weight: bold;
      border: none;
      border-radius: 10px;
      cursor: pointer;
      box-shadow: 0 0 12px var(--accent);
      transition: 0.3s;
    }

    button:hover {
      transform: scale(1.05);
      box-shadow: 0 0 20px var(--primary);
    }

    .voice-control-panel {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background: rgba(0,0,0,0.7);
      border-radius: 50%;
      width: 60px;
      height: 60px;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      z-index: 100;
      box-shadow: 0 0 15px var(--accent);
      transition: all 0.3s ease;
    }

    .voice-control-panel:hover {
      transform: scale(1.1);
      box-shadow: 0 0 25px var(--primary);
    }

    .voice-icon {
      font-size: 30px;
      color: var(--primary);
    }

    .voice-active {
      animation: pulse-icon 1.5s infinite;
    }

    @keyframes pulse-icon {
      0% { transform: scale(1); }
      50% { transform: scale(1.2); }
      100% { transform: scale(1); }
    }

    .voice-tooltip {
      position: absolute;
      background: rgba(0,0,0,0.8);
      color: white;
      padding: 8px 12px;
      border-radius: 8px;
      font-size: 14px;
      bottom: 70px;
      right: 10px;
      opacity: 0;
      transition: opacity 0.3s ease;
      pointer-events: none;
      width: 200px;
      text-align: center;
    }

    .voice-control-panel:hover .voice-tooltip {
      opacity: 1;
    }

    .voice-feedback {
      position: fixed;
      bottom: 100px;
      right: 20px;
      background: rgba(0,0,0,0.7);
      color: white;
      padding: 10px 15px;
      border-radius: 30px;
      z-index: 99;
      max-width: 300px;
      text-align: center;
      opacity: 0;
      transition: opacity 0.3s ease, transform 0.3s ease;
      transform: translateY(20px);
    }

    .voice-feedback.show {
      opacity: 1;
      transform: translateY(0);
    }

    .detection-panel {
      background: var(--card);
      border-radius: 16px;
      border: 1px solid var(--border);
      padding: 20px;
      margin: 20px auto;
      max-width: 800px;
      text-align: left;
    }

    .detection-title {
      font-size: 1.5rem;
      color: var(--accent);
      margin-bottom: 15px;
      text-align: center;
    }

    .detection-text {
      font-size: 1.2rem;
      line-height: 1.5;
      background: rgba(0, 0, 0, 0.3);
      padding: 15px;
      border-radius: 10px;
      max-height: 150px;
      overflow-y: auto;
      margin-bottom: 15px;
    }

    .detection-controls {
      display: flex;
      justify-content: center;
      gap: 15px;
    }

    .scene-description {
      font-style: italic;
      color: var(--accent);
      margin-top: 10px;
    }
  </style>
</head>
<body>
  <h2>üß† Live Object Detection</h2>

  <div class="video-card">
    <img src="{{ url_for('video_feed') }}" alt="Live Object Detection Feed" width="720" height="480" />
    <p>üîä Voice alerts will announce detected objects in real-time.</p>
  </div>

  <div class="detection-panel">
    <h3 class="detection-title">Latest Detection</h3>
    <div class="detection-text" id="detectionText">Waiting for objects to be detected...</div>
    <div class="scene-description" id="sceneDescription">Scene analysis will appear here.</div>
    <div class="detection-controls">
      <button id="repeatDetection">üîä Repeat Last Detection</button>
      <button id="describeScene">üîç Describe Scene</button>
    </div>
  </div>

  <div class="button-group">
    <button id="homeButton">‚¨ÖÔ∏è Back to Home</button>
    <button id="pauseButton">‚è∏Ô∏è Pause Detection</button>
    <button id="helpButton">‚ùì Voice Commands</button>
  </div>

  <!-- Floating voice control button -->
  <div class="voice-control-panel" id="voice-control-btn">
    <div class="voice-icon" id="voice-icon">üéôÔ∏è</div>
    <div class="voice-tooltip">Click for voice commands or press Space</div>
  </div>
  <div class="voice-feedback" id="voice-feedback"></div>

  <script>
    const voiceControlBtn = document.getElementById('voice-control-btn');
    const voiceIcon = document.getElementById('voice-icon');
    const voiceFeedback = document.getElementById('voice-feedback');
    const homeButton = document.getElementById('homeButton');
    const pauseButton = document.getElementById('pauseButton');
    const helpButton = document.getElementById('helpButton');
    const detectionText = document.getElementById('detectionText');
    const sceneDescription = document.getElementById('sceneDescription');
    const repeatDetectionBtn = document.getElementById('repeatDetection');
    const describeSceneBtn = document.getElementById('describeScene');
    
    let recognition;
    let isListening = false;
    let isPaused = false;
    let lastDetectionMessage = "";
    let detectedObjects = [];

    // Initialize speech recognition
    function initSpeechRecognition() {
      if ('webkitSpeechRecognition' in window) {
        recognition = new webkitSpeechRecognition();
        recognition.continuous = false;
        recognition.interimResults = false;
        recognition.lang = 'en-US';
        
        recognition.onstart = function() {
          console.log('Voice recognition started. Speak now.');
          isListening = true;
          voiceIcon.classList.add('voice-active');
          showVoiceFeedback("Listening...");
        };
        
        recognition.onspeechend = function() {
          console.log('Speech recognition ended.');
          isListening = false;
          voiceIcon.classList.remove('voice-active');
          recognition.stop();
        };
        
        recognition.onerror = function(event) {
          console.error('Speech recognition error', event);
          isListening = false;
          voiceIcon.classList.remove('voice-active');
          showVoiceFeedback("Error: " + event.error);
        };
        
        recognition.onresult = function(event) {
          const transcript = event.results[0][0].transcript.toLowerCase();
          console.log('Voice Command:', transcript);
          showVoiceFeedback('Command heard: ' + transcript);
          handleVoiceCommand(transcript);
        };
      }
    }
    
    function startVoiceRecognition() {
      if (!recognition) {
        initSpeechRecognition();
      }
      
      if (recognition) {
        recognition.start();
      } else {
        showVoiceFeedback("Voice recognition not supported in this browser");
        speak("Voice recognition not supported in this browser");
      }
    }
    
    function handleVoiceCommand(command) {
      const lowerCaseCommand = command.toLowerCase().trim();
      console.log("Voice Command Received:", lowerCaseCommand);
      
      if (lowerCaseCommand.includes("go back") || lowerCaseCommand.includes("home") || lowerCaseCommand.includes("return")) {
        speak("Going back to home page.");
        setTimeout(() => window.location.href = '/', 1000);
      } 
      else if (lowerCaseCommand.includes("pause") || lowerCaseCommand.includes("stop detection")) {
        togglePause();
      }
      else if (lowerCaseCommand.includes("resume") || lowerCaseCommand.includes("continue") || lowerCaseCommand.includes("start detection")) {
        togglePause();
      }
      else if (lowerCaseCommand.includes("repeat") || lowerCaseCommand.includes("say again") || lowerCaseCommand.includes("what did you see")) {
        repeatLastDetection();
      }
      else if (lowerCaseCommand.includes("describe") || lowerCaseCommand.includes("tell me about") || lowerCaseCommand.includes("what's in the scene")) {
        describeCurrentScene();
      }
      else if (lowerCaseCommand.includes("help") || lowerCaseCommand.includes("what can i say")) {
        speak("Available commands are: go back or home to return to main page, pause or stop to pause detection, resume or continue to resume detection, repeat to hear the last detection again, describe to get a scene description, and help for available commands.");
      }
      else {
        speak("Command not recognized. Say help for available commands.");
      }
    }
    
    function speak(text) {
      if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.rate = 1;
        utterance.pitch = 1;
        speechSynthesis.cancel(); // Cancel any ongoing speech
        speechSynthesis.speak(utterance);
      }
    }
    
    function showVoiceFeedback(message) {
      voiceFeedback.textContent = message;
      voiceFeedback.classList.add('show');
      
      setTimeout(() => {
        voiceFeedback.classList.remove('show');
      }, 3000);
    }

    // Function to intercept and save voice announcements
    const originalSpeakText = speak;
    window.speakWithTracking = function(text) {
      if (text.includes("I can see:") || text.includes("Multiple objects detected:") || text.includes("Caution!")) {
        lastDetectionMessage = text;
        detectionText.textContent = text;
        updateSceneDescription(text);
      }
      originalSpeakText(text);
    };

    function updateSceneDescription(text) {
      // Extract objects from the text
      detectedObjects = [];
      const objectsRegex = /(?:I can see:|Multiple objects detected:) (.*)/;
      const match = text.match(objectsRegex);
      
      if (match && match[1]) {
        const objectsText = match[1];
        // Extract individual objects, removing position info
        const objectsList = objectsText.split(',').map(item => {
          const objectName = item.replace(/in the (top|bottom) (left|right)/, '').trim();
          return objectName;
        });
        
        detectedObjects = [...new Set(objectsList)]; // Remove duplicates
        
        // Generate scene description
        let scene = "This appears to be ";
        
        if (detectedObjects.includes("person")) {
          scene += "a scene with people";
          if (detectedObjects.includes("car") || detectedObjects.includes("truck")) {
            scene += " near vehicles, possibly outdoors";
          } else if (detectedObjects.includes("chair") || detectedObjects.includes("dining table")) {
            scene += " in a room, possibly indoors";
          }
        } else if (detectedObjects.includes("car") || detectedObjects.includes("truck") || detectedObjects.includes("bicycle")) {
          scene += "an outdoor scene with vehicles";
        } else if (detectedObjects.includes("chair") || detectedObjects.includes("dining table") || detectedObjects.includes("couch")) {
          scene += "an indoor room, possibly a living space or office";
        } else if (detectedObjects.length > 0) {
          scene += `a scene containing ${detectedObjects.join(', ')}`;
        } else {
          scene = "Analyzing the scene...";
        }
        
        sceneDescription.textContent = scene;
      }
    }

    function repeatLastDetection() {
      if (lastDetectionMessage) {
        speak("Repeating last detection: " + lastDetectionMessage);
      } else {
        speak("No objects have been detected yet.");
      }
    }

    function describeCurrentScene() {
      if (detectedObjects.length > 0) {
        speak(sceneDescription.textContent);
      } else {
        speak("I haven't detected enough objects to describe the scene yet.");
      }
    }
    
    function togglePause() {
      isPaused = !isPaused;
      if (isPaused) {
        pauseButton.textContent = "‚ñ∂Ô∏è Resume Detection";
        speak("Detection paused. Voice alerts will be muted.");
        showVoiceFeedback("Detection paused");
      } else {
        pauseButton.textContent = "‚è∏Ô∏è Pause Detection";
        speak("Detection resumed. Voice alerts are active.");
        showVoiceFeedback("Detection resumed");
      }
      
      // Send pause state to server
      fetch('/toggle_detection', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({ paused: isPaused }),
      }).catch(error => console.error('Error:', error));
    }
    
    // Patch the global speak function to track announcements
    // This is a workaround to capture messages from the Flask backend
    const originalSpeech = window.speechSynthesis.speak;
    window.speechSynthesis.speak = function(utterance) {
      if (utterance.text.includes("I can see:") || 
          utterance.text.includes("Multiple objects detected:") || 
          utterance.text.includes("Caution!")) {
        lastDetectionMessage = utterance.text;
        detectionText.textContent = utterance.text;
        updateSceneDescription(utterance.text);
      }
      return originalSpeech.apply(this, arguments);
    };
    
    // Button event listeners
    voiceControlBtn.addEventListener('click', function() {
      if (!isListening) {
        startVoiceRecognition();
      }
    });
    
    homeButton.addEventListener('click', function() {
      window.location.href = '/';
    });
    
    pauseButton.addEventListener('click', togglePause);
    
    helpButton.addEventListener('click', function() {
      speak("Available commands are: go back or home to return to main page, pause or stop to pause detection, resume or continue to resume detection, repeat to hear the last detection again, describe to get a scene description, and help for available commands.");
    });

    repeatDetectionBtn.addEventListener('click', repeatLastDetection);
    
    describeSceneBtn.addEventListener('click', describeCurrentScene);
    
    // Add keyboard shortcut (spacebar) for voice commands
    document.addEventListener('keydown', function(e) {
      if (e.code === 'Space' && !isListening) {
        e.preventDefault(); // Prevent scrolling with space
        startVoiceRecognition();
      }
    });
    
    // Initialize speech recognition
    initSpeechRecognition();
    
    // Announce instructions on page load
    window.addEventListener('load', function() {
      setTimeout(() => {
        speak("Live object detection is active. Voice alerts will announce detected objects with their positions. You can say 'repeat' to hear the last detection again, or 'describe' to get a description of the scene. Say help for more voice commands.");
      }, 1000);
    });
  </script>
</body>
</html>
